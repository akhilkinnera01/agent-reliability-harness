<div align="center">

# ğŸ›¡ï¸ Agent Reliability Harness (ARH)

### SRE for AI Agents â€” Trust, but Verify

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

**Before you deploy an AI agent to production, ask: How reliable is it really?**

<img src="examples/architecture_1.png" alt="ARH Architecture" width="200"/>

</div>

---

## ğŸš€ What is ARH?

ARH is an **end-to-end reliability testing framework** for AI agents. It applies Site Reliability Engineering (SRE) principles to answer the question: *"Is this AI agent safe to deploy?"*

<div align="center">
<img src="examples/flow_1.png" alt="ARH Pipeline" width="200"/>
</div>

### The Problem

AI agents are increasingly making real-world decisions, but we lack standardized ways to measure their reliability:

- âŒ Do they hallucinate under pressure?
- âŒ Are their responses consistent?
- âŒ Can they handle adversarial inputs?
- âŒ Is the knowledge base they use complete?

### The Solution

ARH provides a **Trust Report** that combines:

| Component | What It Measures |
|-----------|------------------|
| **Agent Reliability** | How the model behaves (robustness, consistency, groundedness) |
| **Documentation Quality** | How complete the knowledge base is (finds gaps and flaws) |
| **Trust Score** | Combined metric for deployment readiness |

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ”¬ Reliability Testing
- **Robustness** â€” Prompt perturbation resistance
- **Consistency** â€” Response variance analysis
- **Groundedness** â€” Hallucination detection
- **Predictability** â€” Latency profiling

</td>
<td width="50%">

### ğŸ¯ Adversarial Auditor
- **Proposer** â€” Generates adversarial questions
- **Solver** â€” Document-constrained answering
- **Evaluator** â€” Flaw classification & severity

</td>
</tr>
</table>

### ğŸ“Š Premium Dashboard Output

<div align="center">
<img src="examples/UI_1.png" alt="ARH Dashboard" width="300"/>
</div>

<div align="center">
<img src="examples/UI_2.png" alt="ARH Dashboard" width="300"/>
</div>
---

## ğŸƒ Quick Start

### Installation

```bash
git clone https://github.com/yourusername/agent-reliability-harness.git
cd agent-reliability-harness
pip install -r requirements.txt
```

### Run the Demo

```bash
# Set your API key
export GEMINI_API_KEY="your-key"

# Run premium demo
python3 examples/demo_premium.py
```

### Audit Any Document

```bash
# Supports PDF, DOCX, EPUB, Markdown, and more!
python3 examples/run_on_file.py your_document.pdf
```

---

## ğŸ“– Usage

### Test an AI Agent

```python
from arh.core import UniversalWrapper, ReliabilityHarness

# Create agent wrapper (supports 100+ models via LiteLLM)
agent = UniversalWrapper(model="gemini/gemini-2.5-flash", api_key="...")

# Run reliability tests
harness = ReliabilityHarness(agent)
harness.run_test("robustness", prompts=["What is 2+2?", "Explain quantum computing"])
harness.run_test("consistency", prompts=["What is the capital of France?"])
harness.run_test("groundedness", prompts=["Who invented the telephone?"])

# Get report
report = harness.generate_report()
print(f"Trust Score: {report['overall_score']:.1%}")
print(f"Verdict: {report['verdict']}")
```

### Audit Documentation

```python
from arh.core import UniversalWrapper
from arh.auditor import AdversarialAuditor
from arh.document_loader import load_document

# Load any document format
doc = load_document("safety_manual.pdf")

# Run adversarial audit
agent = UniversalWrapper(model="gemini/gemini-2.5-flash", api_key="...")
auditor = AdversarialAuditor(proposer_model=agent)
report = auditor.audit(doc.content, document_name=doc.filename)

# View findings
for finding in report.findings:
    print(f"[{finding.severity.value}] {finding.flaw_type.value}")
    print(f"  Question: {finding.question}")
    print(f"  Recommendation: {finding.recommendation}")
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agent Reliability Harness                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   AI Agent   â”‚â”€â”€â”€â–¶â”‚ Reliability Tests â”‚â”€â”€â”€â–¶â”‚ Trust Report â”‚   â”‚
â”‚  â”‚  (Any LLM)   â”‚    â”‚  â€¢ Robustness     â”‚    â”‚  â€¢ Score     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ Consistency    â”‚    â”‚  â€¢ Verdict   â”‚   â”‚
â”‚                      â”‚  â€¢ Groundedness   â”‚    â”‚  â€¢ Findings  â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â€¢ Predictability â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  Documents   â”‚â”€â”€â”€â–¶â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                        â”‚
â”‚  â”‚ (PDF/DOCX/)  â”‚    â”‚ Adversarial      â”‚                        â”‚
â”‚  â”‚  EPUB/MD)    â”‚    â”‚ Auditor          â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ Proposer      â”‚                        â”‚
â”‚                      â”‚  â€¢ Solver        â”‚                        â”‚
â”‚                      â”‚  â€¢ Evaluator     â”‚                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ Supported Models

ARH uses **LiteLLM** to support 100+ AI models:

| Provider | Models |
|----------|--------|
| **Google** | Gemini 2.5 Flash, Gemini 2.0, Gemini 1.5 Pro |
| **OpenAI** | GPT-4o, GPT-4, GPT-3.5 Turbo |
| **Anthropic** | Claude 3.5 Sonnet, Claude 3 Opus |
| **Groq** | Llama 3.1, Mixtral |
| **Ollama** | Any local model |
| **+90 more** | AWS Bedrock, Azure, Cohere, etc. |

---

## ğŸ“‚ Project Structure

```
agent-reliability-harness/
â”œâ”€â”€ arh/
â”‚   â”œâ”€â”€ core/           # Agent wrappers, models, harness
â”‚   â”œâ”€â”€ tests/          # Reliability tests
â”‚   â”œâ”€â”€ auditor/        # Adversarial auditor components
â”‚   â”œâ”€â”€ cli/            # CLI commands
â”‚   â”œâ”€â”€ metrics/        # Prometheus exporter
â”‚   â”œâ”€â”€ dashboard.py    # Premium visual output
â”‚   â””â”€â”€ document_loader.py  # Multi-format loader
â”œâ”€â”€ examples/           # Demo scripts
â”œâ”€â”€ docs/               # Documentation
â””â”€â”€ assets/             # Architecture diagrams
```

---

## ğŸ“š Research Lineage

ARH's Adversarial Auditor is inspired by the **Dr. Zero** research paper:

> *"Dr. Zero: A zero-shot approach to adversarial question generation for document evaluation"*

See [docs/DRZERO_CONNECTION.md](docs/DRZERO_CONNECTION.md) for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines first.

```bash
# Run tests
pytest

# Run linting
ruff check arh/
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<div align="center">

**Built with â¤ï¸ for reliable AI**

[Documentation](docs/GETTING-STARTED.md) â€¢ [Examples](examples/) â€¢ [Research](docs/DRZERO_CONNECTION.md)

</div>
